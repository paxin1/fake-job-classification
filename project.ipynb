{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0125a174",
   "metadata": {},
   "source": [
    "# Final Project Demonstration\n",
    "\n",
    "This notebook is a demonstration of the best iterations of models we built over the timeframe of the course. We chose one well-performing model from each of our model algorithms (logistic regression, support vector machine, stacking ensemble, bidirectional LSTM) and use them to predict on a variety of sample job postings in this demo. (You can also try to classify them as well if you want, the text files for each posting are in the inputs folder)\n",
    "\n",
    "note: if this notebook cannot run, an example of the output is saved in project_output.html\n",
    "\n",
    "The full output from the source code including model accuracy comparison used to choose demo models and analytical data is saved in source_output.html.\n",
    "\n",
    "The source code is in a notebook file. Model generations and predictions take a long time to run (apart from logistic regression).\n",
    "\n",
    "All generated models are saved in generated folder, along with the dataframe, vectorizers, and original feature dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234feba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow import keras\n",
    "import contractions\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a258dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tools to process raw text (stem, tokenize, remove stopwords)\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer('\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb4b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to convert text to be compatible with model predictions\n",
    "\n",
    "def create_document(text):\n",
    "    stem = [ps.stem(word.lower()) for word in tokenizer.tokenize(\n",
    "        contractions.fix(text)) if not word.lower() in stop_words]\n",
    "    return ' '.join(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ea0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to read file from directory into python String\n",
    "\n",
    "def readFile(fname):\n",
    "    f = open(fname, 'r', encoding=\"utf8\")\n",
    "    raw_text = f.read()\n",
    "    f.close()\n",
    "    return create_document(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved models and vectorizers from generated folder\n",
    "\n",
    "logistic_model = pickle.load(open('generated/logistic_res_model.pkl', 'rb'))\n",
    "svm_model = pickle.load(open('generated/svm_model_tuned_tfidf.pkl', 'rb'))\n",
    "ensemble_model = pickle.load(open('generated/ensemble_res_model.pkl', 'rb'))\n",
    "lstm_model = keras.models.load_model('generated/lstm_model')\n",
    "\n",
    "Tfidf_vect = pickle.load(open('generated/Tfidf_vect.pkl', 'rb'))\n",
    "vectorizer = pickle.load(open('generated/vectorizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf957452",
   "metadata": {},
   "source": [
    "Sample files are a mix of real and fake job postings.\n",
    "\n",
    "Real: amazon, atlassian, northwestern, wayup\n",
    "\n",
    "Fake: doterra, pacifictransfer, tikehau, cordova, fake_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca15df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run predictions over each selected model from chosen job posting\n",
    "\n",
    "job_text = ''\n",
    "while True:\n",
    "    #process user picked job posting\n",
    "    fname = input('Enter a file(default=\\'atlassian\\', enter \\'quit\\' to stop): ').strip()\n",
    "    try:\n",
    "        if fname == 'quit':\n",
    "            break\n",
    "        elif fname:\n",
    "            job_text = readFile('input/'+fname+'.txt')\n",
    "        else:\n",
    "            job_text = readFile('input/atlassian.txt')\n",
    "\n",
    "        #run predictions on each model using vectorization of user picked job posting\n",
    "        logistic_predictions = logistic_model.predict_proba(\n",
    "            vectorizer.transform([job_text]))\n",
    "        svm_predictions = svm_model.predict_proba(\n",
    "            Tfidf_vect.transform([job_text]))\n",
    "        ens_predictions = ensemble_model.predict_proba(\n",
    "            vectorizer.transform([job_text]))\n",
    "        lstm_predictions = lstm_model.predict(np.array([job_text]))\n",
    "\n",
    "        #output each model's predicted fraudulence probability with 5 siginificant digits\n",
    "        print(\"Fraudulence probability of\", fname)\n",
    "        print(\"\\tLogistic -\\t{0:.5%}\".format(logistic_predictions[0, 1]))\n",
    "        print(\"\\tSVM -\\t\\t{0:.5%}\".format(svm_predictions[0, 1]))\n",
    "        print(\"\\tEnsemble -\\t{0:.5%}\".format(ens_predictions[0, 1]))\n",
    "        print(\"\\tLSTM -\\t\\t{0:.5%}\".format(float(lstm_predictions[0])))\n",
    "        print()\n",
    "    except FileNotFoundError:\n",
    "        print('\\tError: File not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a6426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
